from __future__ import annotations

import logging

import openai
from openai import AsyncAzureOpenAI
from pydantic import BaseModel

logger = logging.getLogger(__name__)

class AzureOpenAIService:
    client: AsyncAzureOpenAI
    model_name: str
    timeout: int

    def __init__(self, api_key: str, endpoint: str, api_version: str, model_name: str) -> None:
        self.model_name = model_name
        self.client = AsyncAzureOpenAI(
            api_key=api_key,
            azure_endpoint=endpoint,
            api_version=api_version,
        )

    async def completion(
        self,
        sys_prompt: str,
        user_prompt: str = "",
        temp: float = 0.1,
        json_format: type[BaseModel] | None = None,
    ) -> str | BaseModel | None:
        messages = [{"role": "system", "content": sys_prompt}]
        if user_prompt:
            messages.append({"role": "user", "content": user_prompt})

        try:
            if json_format is not None:
                completion = await self.client.beta.chat.completions.parse(
                    model=self.model_name,
                    messages=messages,
                    temperature=temp,
                    response_format=json_format,
                )
                return completion.choices[0].message.parsed

            completion = await self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=temp,
            )
            return completion.choices[0].message.content

        except openai.APIError:
            logger.exception("Response couldn't be generated by GPT Model")
            return None
